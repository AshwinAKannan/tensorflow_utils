{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model trained in Keras/TF 2.0\n",
    "# Steps to convert .h5 to .pb format to be able to load model in TF 1.xx cpp code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/tensorflow/tensorflow/issues/29253#issuecomment-530782763"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"I was able to generate a frozen tensorflow model from a TF 2.0 model. First step is to save the weights of the tf.keras model with model.save_weights('xxx.h5').\n",
    "\n",
    "With a conda environment or another computer with TF 1.xx installed (I had 1.14), you generate an untrained tf.keras model identical to the model you want to freeze and load the weights with model.load_weights('xxx.h5').\n",
    "\n",
    "At this point you can save the full model in a h5 file with model.save(...) and then freeze it.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dropout, Lambda, Flatten, Dense, Activation\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization\n",
    "from tensorflow.keras.layers import MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do this step in TF2.0 environment\n",
    "# load model trained in tf2-keras\n",
    "#model = load_model(\"model_unet_checkpoint.h5\")\n",
    "#model.save_weights('result_w.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "IMG_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 7, 7, 512)\n",
      "WARNING:tensorflow:From C:\\Users\\akannan\\AppData\\Local\\conda\\conda\\envs\\tf14\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Build U-Net model\n",
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "\n",
    "s = Lambda(lambda x: (x - 0.0) / 255.0) (inputs)\n",
    "\n",
    "c1 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same', \n",
    "            kernel_regularizer=tf.keras.regularizers.l2(l=0.001)) (s)\n",
    "c1 = BatchNormalization()(c1)\n",
    "c1 = Dropout(0.1) (c1)\n",
    "c1 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(l=0.001)) (c1)\n",
    "c1 = BatchNormalization()(c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(l=0.001)) (p1)\n",
    "c2 = BatchNormalization()(c2)\n",
    "c2 = Dropout(0.1) (c2)\n",
    "c2 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(l=0.001)) (c2)\n",
    "c2 = BatchNormalization()(c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(l=0.001)) (p2)\n",
    "c3 = BatchNormalization()(c3)\n",
    "c3 = Dropout(0.2) (c3)\n",
    "c3 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(l=0.001)) (c3)\n",
    "c3 = BatchNormalization()(c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(l=0.001)) (p3)\n",
    "c4 = BatchNormalization()(c4)\n",
    "c4 = Dropout(0.2) (c4)\n",
    "c4 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(l=0.001)) (c4)\n",
    "c4 = BatchNormalization()(c4)\n",
    "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "c5 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(l=0.001)) (p4)\n",
    "c5 = BatchNormalization()(c5)\n",
    "c5 = Dropout(0.3) (c5)\n",
    "c5 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(l=0.001)) (c5)\n",
    "cbn5 = BatchNormalization() (c5)\n",
    "\n",
    "temp_p4 = MaxPooling2D(pool_size=(2, 2)) (cbn5)\n",
    "temp_c5 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(l=0.001)) (temp_p4)\n",
    "temp_c5 = BatchNormalization()(temp_c5)\n",
    "temp_c5 = Dropout(0.3) (temp_c5)\n",
    "temp_c5 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(l=0.001)) (temp_c5)\n",
    "\n",
    "print(temp_c5.shape)\n",
    "gap_p4 = GlobalAveragePooling2D() (temp_c5)\n",
    "fc1_in = Flatten()(gap_p4)\n",
    "fc1 = Dense(256*2, kernel_regularizer=tf.keras.regularizers.l2(l=0.001))(fc1_in)\n",
    "fc1_relu = Activation(\"relu\")(fc1)\n",
    "fc2_in = Dropout(0.35)(fc1_relu)\n",
    "fc2 = Dense(256*2, kernel_regularizer=tf.keras.regularizers.l2(l=0.001))(fc2_in)\n",
    "fc2_relu = Activation(\"relu\")(fc2)\n",
    "\n",
    "\n",
    "fc3_in = Dropout(0.4)(fc2_relu)\n",
    "fc3 = Dense(256*2,  kernel_regularizer=tf.keras.regularizers.l2(l=0.001))(fc3_in)\n",
    "fc3_relu = Activation(\"relu\")(fc3)\n",
    "\n",
    "fc4_in = Dropout(0.4)(fc3_relu)\n",
    "\n",
    "regression_output_predictions = Dense(4, name=\"regression_output\")(fc4_in)\n",
    "\n",
    "class_output_predictions = Dense(4, activation='softmax', name=\"class_output\")(fc4_in)\n",
    "\n",
    "u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same',\n",
    "                     kernel_regularizer=tf.keras.regularizers.l2(l=0.001)) (cbn5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(l=0.001)) (u6)\n",
    "c6 = BatchNormalization()(c6)\n",
    "c6 = Dropout(0.2) (c6)\n",
    "c6 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(l=0.001)) (c6)\n",
    "c6 = BatchNormalization()(c6)\n",
    "\n",
    "u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same', \n",
    "                     kernel_regularizer=tf.keras.regularizers.l2(l=0.001)) (c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(l=0.001)) (u7)\n",
    "c7 = BatchNormalization()(c7)\n",
    "c7 = Dropout(0.2) (c7)\n",
    "c7 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(l=0.001)) (c7)\n",
    "c7 = BatchNormalization()(c7)\n",
    "\n",
    "u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same',\n",
    "                     kernel_regularizer=tf.keras.regularizers.l2(l=0.001)) (c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(l=0.001)) (u8)\n",
    "c8 = BatchNormalization()(c8)\n",
    "c8 = Dropout(0.1) (c8)\n",
    "c8 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(l=0.001)) (c8)\n",
    "c8 = BatchNormalization()(c8)\n",
    "\n",
    "u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same',\n",
    "                     kernel_regularizer=tf.keras.regularizers.l2(l=0.001)) (c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(l=0.001)) (u9)\n",
    "c9 = BatchNormalization()(c9)\n",
    "c9 = Dropout(0.1) (c9)\n",
    "c9 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(l=0.001)) (c9)\n",
    "c9 = BatchNormalization()(c9)\n",
    "\n",
    "segmentation_output_map = Conv2D(3, (1, 1), activation='sigmoid', name='segmentation_output') (c9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=[inputs], outputs=[segmentation_output_map, regression_output_predictions, class_output_predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('result_w.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('trained_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\"I can now convert the trained model to a frozen pb file with python freeze_model.py --h5 trained_model.h5 --pb trained_model.pb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf14)",
   "language": "python",
   "name": "tf14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
